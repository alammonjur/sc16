Reviewer 1:
Rebuttal Comments: 
The holeReg keeps the address for a new element to be inserted. Instead of adding the new element at the last node, 
the element is kept at the node address resides in holeReg; starting from the root and modify each level accordingly before reaching 
to the final location. By this way, it preserves the min-heap property. This algorithm is presented in section III, 
the algorithm 1.

Weakness Comments:
1. Yes, we should have included and break up these statistics. However, flip-flop used is presented in Table II and SRAM presented at
Table IV in terms of priority bit.
2. Unfortunately, this is a typo, the columns in Table II of LUT and "slice" should interchange the position and hence some other part
of section IVsite.
3. Will remove all typo

Detailed Comments:
To find the path of insertion, we need to know the level of the position of the new node to be inserted.  
Yes, There could have an alternate way to minimize this path delay. By using a special register which can contain the level of next available node. The value of the register can be carefully modified based on insert operation and the holeReg value. To implement this logic need more hardware, and may be, the critical path would be here!  


Reviewer 2:
Rebuttal Comments:
In section III/E/3, we discuss the cost for the implementation of hole minimization for different cases. Yes, we (probably) could have
a breakdown the costs in terms of functionality. But it is not so trivial. For instance, the hole is the output of parallel insert-delete. 
To calculate the cost for insert/delete separate will not make sense. Hole incorporate more hardware. To reduce hole, extra logic is
implemented and extra registers are required. It will be difficult to show the absolute numbers for hole register part, extra logic part
, etc. We can show the overall cost difference (TABLE II and Table III) with the hole and without hole minimization.

Detailed Comments:
The theoretical analysis of cost for the hole is at section II/A (Fig 7). The numerical statistics are given at table II and table III 
where results are shown with and without hole minimization
Search operation should be trivial in our design and without much changing we can do that.

Reviewer 3:
Rebuttal Comments:
1. The throughput is presented in the way so that we can compare our work with others. We could have present operation-per-second. In the case of pipelined design, a total number of operations per second also is not much significance. It should be 1/frequency in our case as each operation executes in a cycle ( section III/D, fig 15).
2. The critical path is on "findNode" function as described in Algorithm 3. It calculates the level where a new node to be inserted. It is O(logx) where 'x' is the last available node location. So definitely, the critical path is proportional to "x" and hence the level.  This is the reason, the frequency varies with different level.
3. The best way to analyze at application level effectiveness is to deploy the technique into a real application.
Unfortunately, we did not have such scope. The performance is highly dependent on the input sequence of instructions as discussed in section III/E/2. The performance of Table II and Table III is based on instruction (insert/delete) sequence generated randomly; the i.e average case is presented.

Detailed Comments:
In section III/E/3, we discuss the cost for the implementation of hole minimization for different cases.
Regarding power consumption, we completely agree with you

Reviewer 4:

1. In the scope of the paper, our paper should belong to:   "Architecture and Networks: All aspects of high-performance hardware including the optimization and evaluation of processors and networks" category where there is several subcategories, particularly, "Parallel and scalable system architecture".
2. 

Detailed Comments:
The two designs of references 2 and 12 are ASIC implementation without the hole concern, and there is no LUT statistics here.


